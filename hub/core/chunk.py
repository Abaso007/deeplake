from hub.core.storage.cachable import Cachable
from typing import List, Tuple
import numpy as np
from io import BytesIO

from hub.core.meta.encode.shape import ShapeEncoder
from hub.core.meta.encode.byte_positions import BytePositionsEncoder

from hub.constants import DEFAULT_CHUNK_MAX_SIZE


class Chunk(Cachable):
    """A Chunk should only be provided data to store in bytes form, alongside the meta information (like shape/num_samples). The
    byte ranges are to be generated by this chunk, and it can also spawn new chunks as needed."""

    def __init__(self, max_data_bytes: int = DEFAULT_CHUNK_MAX_SIZE):
        # no need to load these encoders, if `frombuffer` is called, it will override them.
        self.index_shape_encoder = ShapeEncoder()
        self.index_byte_range_encoder = BytePositionsEncoder()

        self.max_data_bytes = max_data_bytes
        self.min_data_bytes_target = max_data_bytes // 2

        self.data = bytearray()

        self.next_chunk = None

    @property
    def num_samples(self):
        raise NotImplementedError

    @property
    def num_data_bytes(self):
        return len(self.data)

    @property
    def has_space(self):
        return self.num_data_bytes < self.min_data_bytes_target

    def extend(
        self, buffer: bytes, num_samples: int, sample_shape: Tuple[int]
    ) -> Tuple:

        if self.has_space:
            # TODO
            pass

        _validate_buffer(buffer, num_samples)

        num_bytes_per_sample = len(buffer) // num_samples

        self.index_shape_encoder.add_shape(sample_shape, num_samples)
        self.index_byte_range_encoder.add_byte_position(
            num_bytes_per_sample, num_samples
        )

        raise NotImplementedError

    def numpy(self):
        raise NotImplementedError

    def __getitem__(self, sample_index: int):
        raise NotImplementedError

    def __eq__(self, o: object) -> bool:
        raise NotImplementedError

    def __len__(self):
        # TODO: this should not call `tobytes` because it will be slow. should calculate the amount of bytes this chunk takes up in total. (including headers)
        raise NotImplementedError

    def tobytes(self) -> bytes:
        out = BytesIO()
        np.savez(
            out,
            index_shape_encoder=self.index_shape_encoder,
            index_byte_range_encoder=self.index_byte_range_encoder,
            data=self.data,
        )
        out.seek(0)
        return out.read()

    @classmethod
    def frombuffer(cls, buffer: bytes):
        instance = super().frombuffer(buffer)

        # TODO: this should also set `next_chunk`

        raise NotImplementedError
        return instance


def _validate_buffer(buffer: bytes, num_samples: int):
    if num_samples <= 0:
        raise ValueError(
            f"The number of samples a buffer can represent has to be greater than 0. Got {num_samples}"
        )

    if len(buffer) % num_samples != 0:
        raise ValueError(
            f"Buffer length should be perfectly divisible by the number of samples it represents. length={len(buffer)}, num_samples={num_samples}"
        )
